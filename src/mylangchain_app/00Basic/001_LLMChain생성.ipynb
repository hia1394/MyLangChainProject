{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "### LLM Chain 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
   "metadata": {
    "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
   },
   "source": [
    "## 1. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_z\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e09aaca6-5aa2-4b52-bbfc-196e808dc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729d10-9600-415b-b7d1-f954665224e3",
   "metadata": {
    "id": "23729d10-9600-415b-b7d1-f954665224e3"
   },
   "source": [
    "### 1) Prompt + LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OPENAI_API_KEY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# model\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\u001b[39;00m\n\u001b[32m      5\u001b[39m llm = ChatOpenAI(\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     api_key=\u001b[43mOPENAI_API_KEY\u001b[49m,\n\u001b[32m      7\u001b[39m     base_url=\u001b[33m\"\u001b[39m\u001b[33mhttps://api.groq.com/openai/v1\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# Groq API 엔드포인트\u001b[39;00m\n\u001b[32m      8\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mmeta-llama/llama-4-scout-17b-16e-instruct\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# Spring AI와 동일한 모델\u001b[39;00m\n\u001b[32m      9\u001b[39m     temperature=\u001b[32m0.7\u001b[39m\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# chain 실행\u001b[39;00m\n\u001b[32m     13\u001b[39m result = llm.invoke(\u001b[33m\"\u001b[39m\u001b[33m인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'OPENAI_API_KEY' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc4accf-c927-40a3-ba2c-f891c94c34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='인공지능 모델의 학습 원리는 다음과 같습니다.\\n\\n1.  **데이터 수집**: 인공지능 모델이 학습하기 위해서는 많은 양의 데이터가 필요합니다. 이 데이터는 문제에 대한 답을 포함하고 있어야 합니다. 예를 들어, 이미지 분류 모델을 만든다면, 다양한 이미지와 그에 따른 분류 레이블이 필요합니다.\\n2.  **데이터 전처리**: 수집한 데이터를 모델이 학습할 수 있도록 전처리합니다. 예를 들어, 이미지 데이터의 경우, 이미지의 크기를 조정하거나, 노이즈를 제거하는 등의 작업을 수행합니다.\\n3.  **모델 정의**: 인공지능 모델을 정의합니다. 모델은 입력 데이터를 받아서 출력 데이터를 생성하는 함수입니다. 예를 들어, 이미지 분류 모델은 이미지를 입력으로 받아서 이미지의 분류를 출력으로 생성하는 함수입니다.\\n4.  **모델 학습**: 모델을 학습시키기 위해, 모델의 출력과 실제 출력(ground truth)을 비교하여 오류를 계산합니다. 이 오류를 최소화하기 위해 모델의 매개변수를 조정합니다. 이 과정은 반복적으로 수행되며, 모델의 성능이 개선됩니다.\\n5.  **모델 평가**: 학습된 모델의 성능을 평가합니다. 이를 위해, 모델의 출력과 실제 출력을 비교하여 정확도, 정밀도, 재현율 등의 지표를 계산합니다.\\n\\n예를 들어, 고양이와 강아지의 이미지를 분류하는 모델을 만든다고 가정해 보겠습니다. 이 모델은 다음과 같이 학습할 수 있습니다.\\n\\n*   데이터 수집: 고양이와 강아지의 이미지와 그에 따른 분류 레이블(고양이 또는 강아지)을 수집합니다.\\n*   데이터 전처리: 이미지를 모델이 학습할 수 있도록 전처리합니다.\\n*   모델 정의: 이미지를 입력으로 받아서 분류를 출력으로 생성하는 모델을 정의합니다.\\n*   모델 학습: 모델의 출력과 실제 분류를 비교하여 오류를 계산하고, 오류를 최소화하기 위해 모델의 매개변수를 조정합니다.\\n*   모델 평가: 학습된 모델의 성능을 평가하여 정확도, 정밀도, 재현율 등의 지표를 계산합니다.\\n\\n이러한 과정을 통해 인공지능 모델은 학습하고, 주어진 문제에 대해 좋은 성능을 발휘할 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 451, 'prompt_tokens': 24, 'total_tokens': 475, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.199796623, 'prompt_time': 0.000364524, 'completion_time': 1.053851325, 'total_time': 1.054215849}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-cb22718a-8246-4c7b-99f9-2f4c09307a3d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--04568e95-a392-49dc-a897-2adf43c2e420-0' usage_metadata={'input_tokens': 24, 'output_tokens': 451, 'total_tokens': 475, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "WzcZy4PruV1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WzcZy4PruV1n",
    "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "1.  **데이터 수집**: 인공지능 모델이 학습하기 위해서는 많은 양의 데이터가 필요합니다. 이 데이터는 문제에 대한 답을 포함하고 있어야 합니다. 예를 들어, 이미지 분류 모델을 만든다면, 다양한 이미지와 그에 따른 분류 레이블이 필요합니다.\n",
      "2.  **데이터 전처리**: 수집한 데이터를 모델이 학습할 수 있도록 전처리합니다. 예를 들어, 이미지 데이터의 경우, 이미지의 크기를 조정하거나, 노이즈를 제거하는 등의 작업을 수행합니다.\n",
      "3.  **모델 정의**: 인공지능 모델을 정의합니다. 모델은 입력 데이터를 받아서 출력 데이터를 생성하는 함수입니다. 예를 들어, 이미지 분류 모델은 이미지를 입력으로 받아서 이미지의 분류를 출력으로 생성하는 함수입니다.\n",
      "4.  **모델 학습**: 모델을 학습시키기 위해, 모델의 출력과 실제 출력(ground truth)을 비교하여 오류를 계산합니다. 이 오류를 최소화하기 위해 모델의 매개변수를 조정합니다. 이 과정은 반복적으로 수행되며, 모델의 성능이 개선됩니다.\n",
      "5.  **모델 평가**: 학습된 모델의 성능을 평가합니다. 이를 위해, 모델의 출력과 실제 출력을 비교하여 정확도, 정밀도, 재현율 등의 지표를 계산합니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 이미지를 분류하는 모델을 만든다고 가정해 보겠습니다. 이 모델은 다음과 같이 학습할 수 있습니다.\n",
      "\n",
      "*   데이터 수집: 고양이와 강아지의 이미지와 그에 따른 분류 레이블(고양이 또는 강아지)을 수집합니다.\n",
      "*   데이터 전처리: 이미지를 모델이 학습할 수 있도록 전처리합니다.\n",
      "*   모델 정의: 이미지를 입력으로 받아서 분류를 출력으로 생성하는 모델을 정의합니다.\n",
      "*   모델 학습: 모델의 출력과 실제 분류를 비교하여 오류를 계산하고, 오류를 최소화하기 위해 모델의 매개변수를 조정합니다.\n",
      "*   모델 평가: 학습된 모델의 성능을 평가하여 정확도, 정밀도, 재현율 등의 지표를 계산합니다.\n",
      "\n",
      "이러한 과정을 통해 인공지능 모델은 학습하고, 주어진 문제에 대해 좋은 성능을 발휘할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c97fc",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "SeNi_VXqYD-b",
   "metadata": {
    "id": "SeNi_VXqYD-b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01WLucSpYjZt",
   "metadata": {
    "id": "01WLucSpYjZt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \\n\\n기본적으로 인공지능 모델은 데이터를 통해 학습합니다. 예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. 이 모델에게 수많은 고양이와 강아지의 사진을 보여주고, 각 사진이 고양이인지 강아지인지를 알려줍니다. \\n\\n모델은 처음에 고양이와 강아지의 특징을 전혀 모릅니다. 하지만 사진을 보고 답을 하면서, 고양이는 고양이답게 생긴 특징(예: 귀가 뾰족하다, 눈이 크다 등)을 스스로 찾아내고, 강아지도 강아지답게 생긴 특징(예: 귀가 쫑긋 서다, 꼬리가 길다 등)을 찾아냅니다.\\n\\n이 과정을 통해 모델은 점점 더 정확하게 고양이와 강아지를 구분할 수 있게 됩니다. 이것이 바로 인공지능 모델이 학습하는 원리입니다.\\n\\n보다 기술적으로 설명하면, 인공지능 모델은 일반적으로 신경망이라는 구조를 가지고 있습니다. 신경망은 여러 층의 노드(또는 뉴런)로 구성되어 있으며, 각 노드는 입력 데이터를 받아서 출력값을 생성합니다.\\n\\n모델이 학습할 때는, 입력 데이터가 신경망을 통과하면서 각 노드에서 계산된 출력값을 생성합니다. 이 출력값과 실제 답을 비교하여 오류를 계산합니다. 그런 다음, 이 오류를 최소화하기 위해 모델의 가중치를 조정합니다.\\n\\n이 과정은 최적화 알고리즘에 의해 반복적으로 수행되며, 모델의 성능이 개선됩니다. 이렇게 모델이 학습을 마치면, 새로운 데이터를 입력했을 때, 고양이와 강아지를 정확하게 분류할 수 있습니다.\\n\\n결론적으로, 인공지능 모델의 학습 원리는 데이터를 통해 모델이 스스로 특징을 찾아내고, 오류를 최소화하기 위해 가중치를 조정하는 과정입니다. 이를 통해 모델은 점점 더 정확하게 학습을 하게 됩니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 391, 'prompt_tokens': 36, 'total_tokens': 427, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.204402932, 'prompt_time': 0.000515032, 'completion_time': 0.913022887, 'total_time': 0.913537919}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'id': 'chatcmpl-e72882cd-c102-4a53-ae35-ad710b17691b', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--1d468abb-ad72-4bee-b576-ccb510004675-0' usage_metadata={'input_tokens': 36, 'output_tokens': 391, 'total_tokens': 427, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "170ec878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \n",
      "\n",
      "기본적으로 인공지능 모델은 데이터를 통해 학습합니다. 예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. 이 모델에게 수많은 고양이와 강아지의 사진을 보여주고, 각 사진이 고양이인지 강아지인지를 알려줍니다. \n",
      "\n",
      "모델은 처음에 고양이와 강아지의 특징을 전혀 모릅니다. 하지만 사진을 보고 답을 하면서, 고양이는 고양이답게 생긴 특징(예: 귀가 뾰족하다, 눈이 크다 등)을 스스로 찾아내고, 강아지도 강아지답게 생긴 특징(예: 귀가 쫑긋 서다, 꼬리가 길다 등)을 찾아냅니다.\n",
      "\n",
      "이 과정을 통해 모델은 점점 더 정확하게 고양이와 강아지를 구분할 수 있게 됩니다. 이것이 바로 인공지능 모델이 학습하는 원리입니다.\n",
      "\n",
      "보다 기술적으로 설명하면, 인공지능 모델은 일반적으로 신경망이라는 구조를 가지고 있습니다. 신경망은 여러 층의 노드(또는 뉴런)로 구성되어 있으며, 각 노드는 입력 데이터를 받아서 출력값을 생성합니다.\n",
      "\n",
      "모델이 학습할 때는, 입력 데이터가 신경망을 통과하면서 각 노드에서 계산된 출력값을 생성합니다. 이 출력값과 실제 답을 비교하여 오류를 계산합니다. 그런 다음, 이 오류를 최소화하기 위해 모델의 가중치를 조정합니다.\n",
      "\n",
      "이 과정은 최적화 알고리즘에 의해 반복적으로 수행되며, 모델의 성능이 개선됩니다. 이렇게 모델이 학습을 마치면, 새로운 데이터를 입력했을 때, 고양이와 강아지를 정확하게 분류할 수 있습니다.\n",
      "\n",
      "결론적으로, 인공지능 모델의 학습 원리는 데이터를 통해 모델이 스스로 특징을 찾아내고, 오류를 최소화하기 위해 가중치를 조정하는 과정입니다. 이를 통해 모델은 점점 더 정확하게 학습을 하게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848a4c",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 배우고, 예측하거나 결정하는 능력을 키우는 과정이라고 생각하시면 됩니다.\n",
      "\n",
      "기본적으로 인공지능 모델의 학습 과정은 다음과 같습니다:\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해 필요한 데이터를 수집합니다. 이 데이터는 문제에 따라 달라지며, 이미지, 텍스트, 소리 등 다양한 형태가 될 수 있습니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집된 데이터를 모델이 학습할 수 있도록 가공하는 과정입니다. 이 과정에서는 데이터의 잡음 제거, 정규화, 변환 등이 이루어집니다.\n",
      "\n",
      "3. **모델 설정**: 학습을 위해 사용할 인공지능 모델을 설정합니다. 모델의 구조, 파라미터 수, 활성화 함수 등을 결정합니다.\n",
      "\n",
      "4. **학습**: 모델이 수집된 데이터를 통해 학습합니다. 이 과정에서는 모델이 데이터의 패턴이나 관계를 발견하고, 이를 통해 예측이나 분류를 수행할 수 있도록 합니다. 학습 과정에서는 최적화 알고리즘을 사용하여 모델의 파라미터를 조정합니다.\n",
      "\n",
      "5. **평가**: 학습된 모델의 성능을 평가합니다. 이를 통해 모델의 정확도, 정밀도, 재현율 등을 확인하고, 필요에 따라 모델을 수정하거나 학습을 반복합니다.\n",
      "\n",
      "6. **예측**: 학습된 모델을 사용하여 새로운 데이터에 대한 예측이나 분류를 수행합니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. \n",
      "\n",
      "- **데이터 수집**: 다양한 고양이와 강아지의 사진을 수집합니다.\n",
      "- **데이터 전처리**: 사진의 크기를 조정하거나, 노이즈를 제거하는 등의 작업을 수행합니다.\n",
      "- **모델 설정**: 이미지 분류에 적합한 모델을 선택하고, 파라미터를 설정합니다.\n",
      "- **학습**: 모델이 고양이와 강아지의 특징을 학습합니다. 예를 들어, 고양이는 귀가 뾰족하고, 강아지는 귀가 쳐지는 특징을 학습할 수 있습니다.\n",
      "- **평가**: 모델이 고양이와 강아지를 얼마나 정확하게 분류하는지 평가합니다.\n",
      "- **예측**: 새로운 사진을 입력했을 때, 모델이 고양이인지 강아지인지를 예측합니다.\n",
      "\n",
      "이처럼 인공지능 모델은 데이터를 통해 학습하고, 이를 통해 예측이나 분류를 수행하는 능력을 키웁니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain 생성 (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chain의 invoke 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997b16",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "684654e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \n",
      "\n",
      "1. **데이터 수집**: 우선 인공지능이 학습할 데이터를 수집합니다. 예를 들어, 고양이와 강아지의 사진을 인공지능에게 보여주고 고양이와 강아지를 구별하도록 학습시킬 때, 수많은 고양이와 강아지의 사진 데이터를 수집합니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집한 데이터를 깨끗하게 정리하고, 필요한 경우 데이터를 변환하거나 보완하는 작업을 합니다.\n",
      "\n",
      "3. **모델 선택**: 이 데이터를 바탕으로 인공지능 모델을 선택합니다. 예를 들어, 이미지 인식과 같은 작업에는 합성곱 신경망(CNN)과 같은 모델을 사용할 수 있습니다.\n",
      "\n",
      "4. **학습**: 모델에 데이터를 입력하고, 모델이 스스로 데이터를 분석하여 특정 패턴이나 규칙을 찾도록 합니다. 이 과정에서는 '손실 함수(loss function)'라는 것을 사용하여 모델의 성능을 평가합니다. 손실 함수는 모델의 예측 결과와 실제 결과 사이의 차이를 계산합니다.\n",
      "\n",
      "5. **역전파**: 모델의 예측과 실제 결과의 차이가 최소화되도록, '역전파(backpropagation)'라는 알고리즘을 사용하여 모델의 가중치를 조정합니다. 이 과정은 모델이 데이터를 통해 '학습'하는 과정입니다.\n",
      "\n",
      "6. **최적화**: 모델의 성능이 만족할 만한 수준이 될 때까지 4번과 5번의 과정을 반복합니다. 이 과정에서는 '최적화 알고리즘(optimization algorithm)'를 사용하여 모델의 가중치를 업데이트합니다.\n",
      "\n",
      "7. **평가**: 모델의 학습이 완료되면, 별도의 테스트 데이터를 사용하여 모델의 성능을 평가합니다.\n",
      "\n",
      "8. **배포**: 모델의 성능이 만족할 만한 수준이면, 실제 환경에 배포하여 사용할 수 있습니다.\n",
      "\n",
      "이렇게 인공지능 모델은 데이터를 통해 학습하고, 그 데이터를 바탕으로 예측이나 분류 작업을 수행할 수 있습니다."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "lm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188674-915f-41af-ac46-56f9f54289b0",
   "metadata": {
    "id": "b0188674-915f-41af-ac46-56f9f54289b0"
   },
   "source": [
    "##### 2) Multiple Chains\n",
    "* Multi Chain을 활용한 영화 추천 및 줄거리 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
    "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " ===> 추천된 영화:\n",
      "'월-E'(2008)는 톰 행크스가 주연한 영화로 인공지능 로봇 월-E와 EVE의 이야기를 그린 애니메이션 영화입니다. 이 영화는 미래의 인류가 직면할 수 있는 환경 문제와 인간의 존재에 대한 깊은 성찰을 담고 있습니다. 영화의 메시지와 감동적인 장면들이 많은 이들의 마음을 사로잡았습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # 영화 제목 얻기\n",
    "\n",
    "print(type(movie))\n",
    "print(\" ===> 추천된 영화:\")  # movie 값 출력\n",
    "print(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16718b76-f59d-48f7-906f-5d2371417803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "16718b76-f59d-48f7-906f-5d2371417803",
    "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001A886AE5640>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001A886A62B40>, root_client=<openai.OpenAI object at 0x000001A886AE6390>, root_async_client=<openai.AsyncOpenAI object at 0x000001A886AE6D20>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001A886AE5640>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001A886A62B40>, root_client=<openai.OpenAI object at 0x000001A886AE6390>, root_async_client=<openai.AsyncOpenAI object at 0x000001A886AE6D20>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "🔹 영화 줄거리 요약:\n",
      " ## 영화 정보\n",
      "\n",
      "*   **영화:** 원더\n",
      "*   **장르:** 드라마\n",
      "*   **감독:** 스티븐 츄보스키 \n",
      "*   **출연:** 제이콥 트렘블레이, 오웬 윌슨, 줄리아 로버츠 \n",
      "\n",
      "## 줄거리\n",
      "\n",
      "소아과 의사인 어머니와 아버지는 태어날 때부터 얼굴에 기형이 있는 아들을 키웁니다. 아들은 10살이 되고, 초등학교에 입학하게 됩니다. 아들은 학교에 처음 입학했을 때 많은 어려움을 겪지만, 결국 친구들과 선생님들의 도움을 받아 학교생활을 잘하게 됩니다. 아들은 자신이 가진 기형에 대해 당당하게 이야기하고, 다른 사람들과의 소통을 통해 자신감을 얻습니다.\n",
      "\n",
      "## 추천 이유\n",
      "\n",
      "이 영화는 드라마 장르의 영화로, 삶의 어려움을 겪는 주인공이 자신의 꿈을 이루는 과정과 그 속에서 겪는 성장과 성숙의 과정을 감동적으로 묘사하고 있습니다. 또한, 이 영화는 삶의 어려움에 직면했을 때 포기하지 않고 노력하는 자세의 중요성을 강조하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb684fd",
   "metadata": {},
   "source": [
    "##### chain1과 chain2에서 영화 제목이 일관되게 전달 되도록 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30883ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 영화 줄거리 요약:\n",
      "('영화: <매드 맥스: 분노의 질주>\\n'\n",
      " '\\n'\n",
      " '장르: 액션, 드라마, 코미디\\n'\n",
      " '\\n'\n",
      " '줄거리: 맥스 로킨스턴은 고속도로 경부대로 근무하던 중, 오일 필드에서 일하던 일당이 사제 총기를 쏴대며 나타납니다. 이후 맥스는 '\n",
      " '도망치던 중, 토레타가의 여주인 임퍼레이터 퓨리오사에게 구조를 받게 됩니다. 하지만 토레타가에는 퓨리오사가 잡혀 있는 상태였고, '\n",
      " '퓨리오사는 자기가 이끄는 부족을 구하기 위해 고향으로 돌아가려던 중이었습니다. 맥스는 퓨리오사의 부족과 함께 퓨리오사의 고향으로 돌아가는 '\n",
      " '여정에 동행하게 됩니다. 하지만 그들의 여정에 토레타가의 수장인 이모터란이 방해를 가합니다.\\n'\n",
      " '\\n'\n",
      " '감독: 조지 밀러\\n'\n",
      " '\\n'\n",
      " '캐스팅: \\n'\n",
      " '- 톰 하디 (맥스 역)\\n'\n",
      " '- 샤를리즈 테론 (임퍼레이터 퓨리오사 역)\\n'\n",
      " '- 니콜라스 홀트 (임모탄 조 역)\\n'\n",
      " '\\n'\n",
      " '추천 이유: 영화는 고옥탄 액션과 유머러스한 장면으로 가득 차 있습니다. 주인공인 맥스는 과거의 트라우마를 극복하고 새로운 동료들과 함께 '\n",
      " '성장하는 모습을 보여줍니다. 또한, 영화는 사막에서 벌어지는 자동차 경주와 폭주 장면으로 눈을 사로잡습니다.')\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\")\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-unC8AIy--py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
